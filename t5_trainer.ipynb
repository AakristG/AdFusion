{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b9df1d",
   "metadata": {},
   "source": [
    "Install the required Python libraries and frameworks (Torch is assumed to be install in your virtual environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentencepiece\n",
    "%pip install transformers\n",
    "%pip install rich[jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007093d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e3040",
   "metadata": {},
   "source": [
    "This is the script that gathers data from the different folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cde4b4-c92a-4c0a-9249-311778649d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Generate captions.txt file with token filtering\n",
    "\n",
    "base_path = \"data\" \n",
    "output_file = os.path.join(base_path, \"captions.txt\")\n",
    "\n",
    "# Open the output file to write the image paths and captions\n",
    "with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "    # Loop through each numbered subfolder\n",
    "    for subdir in os.listdir(base_path):\n",
    "        subfolder_path = os.path.join(base_path, subdir)\n",
    "\n",
    "        # Check if the path is a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            print(f\"Processing subfolder: {subfolder_path}\")\n",
    "\n",
    "            # List files in the current subfolder for debugging\n",
    "            files_in_subfolder = os.listdir(subfolder_path)\n",
    "            print(f\"Files in {subfolder_path}: {files_in_subfolder}\")\n",
    "\n",
    "            image_path = os.path.join(subfolder_path, 'img.jpg')\n",
    "            caption_path = os.path.join(subfolder_path, 'captions.txt')\n",
    "\n",
    "            print(f\"Looking for image: {image_path}\")\n",
    "            print(f\"Looking for caption: {caption_path}\")\n",
    "\n",
    "            # Check if both files exist\n",
    "            if os.path.exists(image_path) and os.path.exists(caption_path):\n",
    "                try:\n",
    "                    with open(caption_path, 'r', encoding='utf-8') as f_caption:\n",
    "                        caption = f_caption.read().replace('\\n', ' ').strip()\n",
    "\n",
    "                        # Tokenize caption and check token length\n",
    "                        tokens = caption.split()\n",
    "                        if 10 <= len(tokens) <= 512:\n",
    "                            # Write image path and valid caption to output file\n",
    "                            f_out.write(f\"{image_path}\\t{caption}\\n\")\n",
    "                            print(f\"Found image and caption. Writing to file: {image_path}\\t{caption}\\n\")\n",
    "                        else:\n",
    "                            print(f\"Caption in {caption_path} does not meet token length requirements (10-512 tokens). SKIP THIS FILE.\")\n",
    "\n",
    "                except UnicodeDecodeError as e:\n",
    "                    print(f\"Error reading caption file {caption_path}: {e}\")\n",
    "            else:\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"Image file does not exist: {image_path}\")\n",
    "                if not os.path.exists(caption_path):\n",
    "                    print(f\"Caption file does not exist: {caption_path}\")\n",
    "\n",
    "print(f\"Captions file created at {output_file}\")\n",
    "\n",
    "# Step 2: Load the captions.txt into a DataFrame\n",
    "\n",
    "input_file = output_file\n",
    "df = pd.read_csv(input_file, delimiter='\\t', header=None, names=['image_path', 'caption'])\n",
    "\n",
    "# Check the DataFrame structure and contents\n",
    "print(\"DataFrame structure:\")\n",
    "print(df.info())  # This will show the column names and types\n",
    "print(\"DataFrame contents:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 3: Sample rows from the DataFrame if not empty\n",
    "\n",
    "if not df.empty:\n",
    "    sampled_df = df.sample(n=1)  # Sample a single random row\n",
    "    print(\"Sampled DataFrame row:\")\n",
    "    print(sampled_df)\n",
    "else:\n",
    "    print(\"The DataFrame is empty. Check if captions.txt has valid entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd17a57-777b-49ea-85a6-08885b4b532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the captions.txt file exists and read its contents\n",
    "output_file = \"data/captions.txt\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        contents = f.read()\n",
    "        print(contents)  # Print the contents to see if it's populated\n",
    "else:\n",
    "    print(\"File does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6cf37",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ffb25",
   "metadata": {},
   "source": [
    "Confirmation that the data was changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa925d-b326-4573-81d0-007edb5bd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This just checks if the data actually got stored where we want it to be\n",
    "print(\"Shape of DataFrame:\", df.shape)\n",
    "print(df.head())  # Show the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229040b-d274-41ea-af5c-d071e3b3cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33772c48-0b15-4f09-b800-c2148f864248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame Columns:\", df.columns)\n",
    "print(\"First few rows of DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeff84a-7f33-4616-a70e-c724d22bd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(f\"Image Path: {row['image_path']}, Caption: {row['caption']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2811b90e-4f89-46d9-9b6f-a614846506a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"caption\"] = df[\"caption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631eda03-ac8a-4649-9ca2-8dbc4a7c6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5a831",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd583eb",
   "metadata": {},
   "source": [
    "Now we use PyTorch to set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2100b-a737-45ca-b4ff-eb833829c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os  # For operating system interactions\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import torch  # Core PyTorch library\n",
    "import torch.nn.functional as F  # For various activation functions and neural network utilities\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler  # For data loading utilities\n",
    "\n",
    "# Importing T5 model and tokenizer from Hugging Face transformers library\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Importing rich library for better console output formatting\n",
    "from rich.table import Column, Table  # For displaying tables in the console\n",
    "from rich import box  # For setting table borders\n",
    "from rich.console import Console  # Console class for logging\n",
    "\n",
    "# Define a rich console logger to format and display outputs\n",
    "console = Console(record=True)\n",
    "\n",
    "def display_df(df):\n",
    "    \"\"\"Display a DataFrame in an ASCII table format using rich library.\"\"\"\n",
    "\n",
    "    # Create a console for output\n",
    "    console = Console()\n",
    "    \n",
    "    # Define the table structure with two columns, aligning text in the center\n",
    "    table = Table(Column(\"source_text\", justify=\"center\"), Column(\"target_text\", justify=\"center\"), title=\"Sample Data\", pad_edge=False, box=box.ASCII)\n",
    "\n",
    "    # Iterate over each row in the DataFrame and add it to the table\n",
    "    for i, row in enumerate(df.values.tolist()):\n",
    "        table.add_row(row[0], row[1])\n",
    "\n",
    "    # Print the table to the console\n",
    "    console.print(table)\n",
    "\n",
    "# Define a table for logging training status with columns for epoch, steps, and loss\n",
    "training_logger = Table(\n",
    "    Column(\"Epoch\", justify=\"center\"),\n",
    "    Column(\"Steps\", justify=\"center\"),\n",
    "    Column(\"Loss\", justify=\"center\"),\n",
    "    title=\"Training Status\",\n",
    "    pad_edge=False,\n",
    "    box=box.ASCII\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca4169",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdba40a",
   "metadata": {},
   "source": [
    "Check for CUDA (not recommended to run in CPU unless if you have a gaming laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f415d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7096ef-de11-4f2b-a76e-a346f7520d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourDataSetClass(Dataset):\n",
    "    \n",
    "    # Custom dataset class for preparing and loading data into the DataLoader to be passed to the neural network for fine-tuning.\n",
    "  \n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
    "        # Initialize tokenizer and dataset attributes\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = target_len\n",
    "        self.target_text = self.data[target_text]  # Target text column in the dataset\n",
    "        self.source_text = self.data[source_text]  # Source text column in the dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset (number of samples)\n",
    "        return len(self.target_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get source and target text for the given index, ensuring they are in string format\n",
    "        source_text = str(self.source_text[index])\n",
    "        target_text = str(self.target_text[index])\n",
    "\n",
    "        # Clean and preprocess the text data\n",
    "        source_text = ' '.join(source_text.split())\n",
    "        target_text = ' '.join(target_text.split())\n",
    "\n",
    "        # Tokenize the source text\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [source_text],\n",
    "            max_length=self.source_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize the target text\n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [target_text],\n",
    "            max_length=self.summ_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Extract token IDs and attention masks for source and target\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        # Return a dictionary of tensors with source and target data\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long),\n",
    "            'source_mask': source_mask.to(dtype=torch.long),\n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)  # Target IDs for the model's output\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef5709-c88b-47a0-83bf-bde950544c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    # Function to perform training for a single epoch.\n",
    "\n",
    "\n",
    "    # Set the model to training mode (enables dropout, etc.)\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over each batch of data in the training DataLoader\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        # Move target IDs to the specified device and separate labels and decoder inputs\n",
    "        y = data['target_ids'].to(device, dtype=torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()  # Decoder input IDs (shifted to the left)\n",
    "        lm_labels = y[:, 1:].clone().detach()  # Target labels shifted to the right\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100  # Ignore padding tokens in the loss calculation\n",
    "\n",
    "        # Move source IDs and attention masks to the specified device\n",
    "        ids = data['source_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass through the model to compute the output and loss\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]  # Extract the loss from the model output\n",
    "\n",
    "        # Print training progress every 10 batches\n",
    "        if _ % 10 == 0:\n",
    "            training_logger.add_row(str(epoch), str(_), str(loss))\n",
    "            console.print(training_logger)\n",
    "\n",
    "        # Backpropagation: reset gradients, compute gradients, and update model parameters\n",
    "        optimizer.zero_grad()  # Clear existing gradients\n",
    "        loss.backward()        # Backpropagate the loss\n",
    "        optimizer.step()       # Update model parameters based on gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81166e8-f369-4e6e-ad99-e1042b48fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    \n",
    "    #Function to evaluate model for predictions on a validation dataset.\n",
    "    \n",
    "\n",
    "    # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []  # List to store generated predictions\n",
    "    actuals = []      # List to store actual target sequences\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            # Extract target IDs and source inputs, and move them to the specified device\n",
    "            y = data['target_ids'].to(device, dtype=torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype=torch.long)\n",
    "\n",
    "            # Generate predictions using the model with specified generation parameters\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "                max_length=150,\n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5,\n",
    "                length_penalty=1.0,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "            # Decode generated IDs to text predictions and target sequences\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in y]\n",
    "\n",
    "            # Print progress for every 10 batches processed\n",
    "            if _ % 10 == 0:\n",
    "                console.print(f'Completed {_}')\n",
    "\n",
    "            # Append predictions and actual target sequences for evaluation\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "\n",
    "    # Return the lists of predictions and actuals for comparison\n",
    "    return predictions, actuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf118e-c718-4b37-93cc-923c41f7ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T5Trainer(\n",
    "    dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\"\n",
    "):\n",
    "\n",
    "    #T5 Trainer\n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.\n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Importing the raw dataset\n",
    "    dataframe = dataframe[[source_text, target_text]]\n",
    "    display_df(dataframe.head(2))\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest for validation.\n",
    "    train_size = 0.8\n",
    "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
    "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = YourDataSetClass(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "    val_set = YourDataSetClass(\n",
    "        val_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    val_params = {\n",
    "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "    console.log(f\"[Saving Model]...\\n\")\n",
    "    # Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "    # evaluating test dataset\n",
    "    console.log(f\"[Initiating Validation]...\\n\")\n",
    "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\n",
    "\n",
    "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
    "\n",
    "    console.log(f\"[Validation Completed.]\\n\")\n",
    "    console.print(\n",
    "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
    "    )\n",
    "    console.print(\n",
    "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
    "    )\n",
    "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224823e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447efeef",
   "metadata": {},
   "source": [
    "If you want to train t5-base instead of t5-large, change the model name to t5-base and change both of the batch size to 8. We use one in the code so CUDA can allocate enough memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5f2d6-8ef9-49c9-b470-5f572cbb08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"MODEL\":\"t5-large\",             # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\":1,          # training batch size  - > batch size has to be 1 or 2 if using t-5 large (for t5-base it should be 8)\n",
    "    \"VALID_BATCH_SIZE\":1,          # validation batch size - > batch size has to be 1 or 2 if using t-5 large (for t5-base it should be 8)\n",
    "    \"TRAIN_EPOCHS\":3,              # number of training epochs\n",
    "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\":512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\":50,   # max length of target text\n",
    "    \"SEED\": 42                     # set seed for reproducibility\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e3f4d1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53777f",
   "metadata": {},
   "source": [
    "More confirmation that the data was changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5c58e-5d96-40e3-bf8c-b23a8aa17ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns) #checking to see if data was parsed and changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e31dc0-f1ff-42e7-a9f0-9b196bcc6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'image_path': 'text', 'caption': 'headlines'}, inplace=True) #rename the files if you are too lazy to individually go through change every file name in your Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45227958-9634-4870-ad87-4e653e2183cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new column names\n",
    "print(\"Renamed DataFrame columns:\") #checking to see if data was parsed and changed correctly\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28050d3e",
   "metadata": {},
   "source": [
    "This is the line that fine tunes the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f54229-e61c-4f26-b0e9-a67e4131444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T5Trainer(dataframe=df[:500], source_text=\"text\", target_text=\"headlines\", model_params=model_params, output_dir=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7145e574",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "399372f3",
   "metadata": {},
   "source": [
    "More confirmation that the data was changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e0b83-3d30-4ea5-8b88-e017527a5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column names in df_predictions:\", df.columns.tolist()) #checking to see if data was parsed and changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056d5c1-0a1c-4740-a430-1beae6efc058",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns) #checking to see if data was parsed and changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33496cb9-ed82-40ec-8a99-5c23487ff9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'headlines' in df.columns:\n",
    "    df['input'] = \"Summarize this: \" + df['headlines']\n",
    "else:\n",
    "    print(\"Caption column not found. Check the DataFrame structure.\") #checking to see if data was parsed and changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ffa32b-3e88-4007-89be-e6925f3db7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input'] = \"Summarize this: \" + df['headlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2fb32-64d7-41a9-b3fc-54f8643d594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['input'].apply(len))  # Check lengths of input strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db261e7-7827-4be4-8b02-a445ebfa5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df) #checking to see if data was parsed and changed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41251801-3757-4bda-bfa1-dab1cb5751d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['headlines'])\n",
    "print(df['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60aaf1d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62949c64",
   "metadata": {},
   "source": [
    "Since the model prediction and generated text are in captions.txt (which was created by the system), we get outputs from the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the captions.txt into a DataFrame\n",
    "input_file = \"/content/drive/My Drive/LaVi-Bridge/captions.txt\"\n",
    "df_predictions = pd.read_csv(input_file, delimiter='\\t', header=None, names=['image_path', 'caption'])\n",
    "\n",
    "# Confirm the DataFrame was loaded correctly\n",
    "print(\"DataFrame loaded. Contents:\")\n",
    "print(df_predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704d7fa",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dad9ef",
   "metadata": {},
   "source": [
    "This is the script to print the generated output alongside the actual output that was stored in the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11850f11-c98d-4f81-86b6-b9ecf6ae10a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "# Assuming model and tokenizer are defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)  # Move model to device\n",
    "\n",
    "df_predictions['input'] = df_predictions['caption']\n",
    "\n",
    "def generate_summary(text):\n",
    "    try:\n",
    "        inputs = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "        summary_ids = model.generate(inputs, max_length=150, num_beams=4, early_stopping=True)\n",
    "        generated_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # Remove consecutive duplicate phrases in generated text\n",
    "        unique_summary = re.sub(r'\\b(\\w+\\s+){2,}(\\w+\\s+)+\\1\\b', r'\\1', generated_text.strip())\n",
    "\n",
    "        # Truncate at the first occurrence of \"!\" or \"...\" -> this fixed the problem where the model would repeat itself over and over again about some generated text\n",
    "        truncated_summary = re.split(r'(!|\\.\\.\\.)', unique_summary, maxsplit=1)[0]\n",
    "\n",
    "        # Split into sentences and get at least 2-3 sentences if possible\n",
    "        sentences = re.split(r'(?<=[.!?]) +', truncated_summary)\n",
    "        if len(sentences) < 3:\n",
    "            # If fewer than 3 sentences, use them all; otherwise, limit to first 3\n",
    "            final_summary = ' '.join(sentences)\n",
    "        else:\n",
    "            final_summary = ' '.join(sentences[:3])\n",
    "\n",
    "        return final_summary.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary for text: {text}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"\"  # Return an empty string in case of error\n",
    "\n",
    "# Apply the summary generation\n",
    "df_predictions['Generated Text'] = df_predictions['input'].apply(generate_summary)\n",
    "\n",
    "# Now print the generated summaries\n",
    "print(\"Generated Summaries and Actual Texts:\")\n",
    "for index, row in df_predictions.iterrows():\n",
    "    generated_text = row['Generated Text'] if 'Generated Text' in df_predictions.columns else \"Not Generated\"\n",
    "    actual_text = row['caption']  # or row['Actual Text'] if that was in your previous DataFrame\n",
    "    print(f\"Entry {index + 1}:\")\n",
    "    print(f\"Generated Summary: {generated_text}\")\n",
    "    print(f\"Actual Summary: {actual_text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
